{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from igraph import *\n",
    "\n",
    "# Import and start a Spark session.\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "import string\n",
    "from collections import Counter\n",
    "from nltk.util import everygrams\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/egj/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet:\n",
    "    def __init__(_id,user,tweet):\n",
    "        \n",
    "        self.id = _id\n",
    "        self.username = user\n",
    "        self.tweet = tweet\n",
    "    \n",
    "    def extract_hashtags(tweet):\n",
    "        \n",
    "        pos = [pos for pos,char in enumerate(tweet) if char =='#']\n",
    "        pos1 = [string.find(' ',p) for p in pos]\n",
    "        indices = list(zip(pos,pos1))\n",
    "        hashtags = [tweet[p[0]+1:p[1]] for p in indices]\n",
    "        return hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init(_id,user):\n",
    "        self.id = _id\n",
    "        self.username = user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_username_from_link(link):\n",
    "    return link.split('/')[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'tweets-notmypresident.json'\n",
    "data = spark.read.json(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conversation_id', 'created_at', 'date', 'gif_thumb', 'gif_url', 'has_parent_tweet', 'hashtags', 'id', 'is_quote_status', 'is_reply_to', 'likes_count', 'link', 'location', 'mentions', 'name', 'photos', 'place', 'quote_id', 'quote_url', 'replies', 'replies_count', 'retweet', 'retweets_count', 'tags', 'time', 'timezone', 'tweet', 'urls', 'user_id', 'username', 'video_thumb', 'video_url']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/egj/anaconda3/envs/ada/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1159, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/egj/anaconda3/envs/ada/lib/python3.7/site-packages/py4j/java_gateway.py\", line 985, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/egj/anaconda3/envs/ada/lib/python3.7/site-packages/py4j/java_gateway.py\", line 1164, in send_command\n",
      "    \"Error while receiving\", e, proto.ERROR_ON_RECEIVE)\n",
      "py4j.protocol.Py4JNetworkError: Error while receiving\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)\n",
    "pd_data = data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>gif_thumb</th>\n",
       "      <th>gif_url</th>\n",
       "      <th>has_parent_tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>id</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>is_reply_to</th>\n",
       "      <th>...</th>\n",
       "      <th>retweets_count</th>\n",
       "      <th>tags</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>tweet</th>\n",
       "      <th>urls</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>video_thumb</th>\n",
       "      <th>video_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>804112748397424640</td>\n",
       "      <td>1480550393000</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>[#notmypresident, #dumptrump]</td>\n",
       "      <td>804112748397424640</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>00:59:53</td>\n",
       "      <td>CET</td>\n",
       "      <td>Unfortunately @realDonaldTrump doesn't underst...</td>\n",
       "      <td>[https://twitter.com/washingtonpost/status/804...</td>\n",
       "      <td>25591312</td>\n",
       "      <td>i_create_things</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804112672203669504</td>\n",
       "      <td>1480550375000</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>[#notmypresident, #stillwithher]</td>\n",
       "      <td>804112672203669504</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>00:59:35</td>\n",
       "      <td>CET</td>\n",
       "      <td>.@maddow U R the only one that can keep me awa...</td>\n",
       "      <td>[https://twitter.com/frankthorp/status/8040876...</td>\n",
       "      <td>27801842</td>\n",
       "      <td>jenk264</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>804061970819403776</td>\n",
       "      <td>1480550367000</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>[#twousefulidiots, #notmypresident]</td>\n",
       "      <td>804112641002192897</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>00:59:27</td>\n",
       "      <td>CET</td>\n",
       "      <td>@TheLastWord As if the VA doesn't have enough ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>522508993</td>\n",
       "      <td>rebelwriter57</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>804110522027126784</td>\n",
       "      <td>1480550358000</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>[#notmypresident]</td>\n",
       "      <td>804112600380407809</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>[]</td>\n",
       "      <td>00:59:18</td>\n",
       "      <td>CET</td>\n",
       "      <td>God help us we've become an oligarchy. #NotMyP...</td>\n",
       "      <td>[]</td>\n",
       "      <td>21827563</td>\n",
       "      <td>kbates1948</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>804112446868910081</td>\n",
       "      <td>1480550321000</td>\n",
       "      <td>2016-12-01</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>[#notmypresident, #auditthevote, #grabyourwall...</td>\n",
       "      <td>804112446868910081</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>00:58:41</td>\n",
       "      <td>CET</td>\n",
       "      <td>#notmypresident #AuditTheVote #GrabYourWallet ...</td>\n",
       "      <td>[https://twitter.com/funder/status/80287292326...</td>\n",
       "      <td>798296697952735233</td>\n",
       "      <td>bonecho5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      conversation_id     created_at        date gif_thumb gif_url  \\\n",
       "0  804112748397424640  1480550393000  2016-12-01                     \n",
       "1  804112672203669504  1480550375000  2016-12-01                     \n",
       "2  804061970819403776  1480550367000  2016-12-01                     \n",
       "3  804110522027126784  1480550358000  2016-12-01                     \n",
       "4  804112446868910081  1480550321000  2016-12-01                     \n",
       "\n",
       "   has_parent_tweet                                           hashtags  \\\n",
       "0                 0                      [#notmypresident, #dumptrump]   \n",
       "1                 0                   [#notmypresident, #stillwithher]   \n",
       "2                 1                [#twousefulidiots, #notmypresident]   \n",
       "3                 1                                  [#notmypresident]   \n",
       "4                 0  [#notmypresident, #auditthevote, #grabyourwall...   \n",
       "\n",
       "                   id  is_quote_status  is_reply_to    ...     retweets_count  \\\n",
       "0  804112748397424640                1            0    ...                  0   \n",
       "1  804112672203669504                1            0    ...                  0   \n",
       "2  804112641002192897                0            1    ...                  0   \n",
       "3  804112600380407809                0            1    ...                 31   \n",
       "4  804112446868910081                1            0    ...                  1   \n",
       "\n",
       "  tags      time timezone                                              tweet  \\\n",
       "0   []  00:59:53      CET  Unfortunately @realDonaldTrump doesn't underst...   \n",
       "1   []  00:59:35      CET  .@maddow U R the only one that can keep me awa...   \n",
       "2   []  00:59:27      CET  @TheLastWord As if the VA doesn't have enough ...   \n",
       "3   []  00:59:18      CET  God help us we've become an oligarchy. #NotMyP...   \n",
       "4   []  00:58:41      CET  #notmypresident #AuditTheVote #GrabYourWallet ...   \n",
       "\n",
       "                                                urls             user_id  \\\n",
       "0  [https://twitter.com/washingtonpost/status/804...            25591312   \n",
       "1  [https://twitter.com/frankthorp/status/8040876...            27801842   \n",
       "2                                                 []           522508993   \n",
       "3                                                 []            21827563   \n",
       "4  [https://twitter.com/funder/status/80287292326...  798296697952735233   \n",
       "\n",
       "          username video_thumb video_url  \n",
       "0  i_create_things                        \n",
       "1          jenk264                        \n",
       "2    rebelwriter57                        \n",
       "3       kbates1948                        \n",
       "4         bonecho5                        \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges():\n",
    "    retweets = pd_data[pd_data.loc[:,'is_quote_status'].map(lambda q: q==1)]\n",
    "    first_users = retweets.loc[:,'quote_url'].map(lambda quote:extract_username_from_link(quote))\n",
    "    retweeters = retweets.loc[:,'username']\n",
    "    edges = list(zip(first_users,retweeters))\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = get_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will change this for loop latter\n",
    "# Assign an id to the vertices (needed for the graph)\n",
    "user_id = 0\n",
    "map_user_id = {}\n",
    "for edge in edges:\n",
    "    for i in range(2):\n",
    "        if edge[i] not in map_user_id.keys():\n",
    "            map_user_id[edge[i]] = user_id\n",
    "            user_id +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_to_id(e):\n",
    "    return (map_user_id[e[0]],map_user_id[e[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the graph for the retweets\n",
    "g = Graph()\n",
    "g.add_vertices(user_id)\n",
    "edges_id = list(map(lambda e: edge_to_id(e),edges))\n",
    "g.add_edges(edges_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = g.pagerank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "realDonaldTrump\n"
     ]
    }
   ],
   "source": [
    "ind = pr.index(np.max(pr))\n",
    "most_influential = ''\n",
    "\n",
    "for k,v in map_user_id.items():\n",
    "    if v == ind:\n",
    "        most_influential = k\n",
    "        \n",
    "print(most_influential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = g.layout(\"rt\", 2)\n",
    "plot(g, layout = layout).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['conversation_id', 'created_at', 'date', 'gif_thumb', 'gif_url',\n",
       "       'has_parent_tweet', 'hashtags', 'id', 'is_quote_status', 'is_reply_to',\n",
       "       'likes_count', 'link', 'location', 'mentions', 'name', 'photos',\n",
       "       'place', 'quote_id', 'quote_url', 'replies', 'replies_count', 'retweet',\n",
       "       'retweets_count', 'tags', 'time', 'timezone', 'tweet', 'urls',\n",
       "       'user_id', 'username', 'video_thumb', 'video_url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tokens(tweet_list):\n",
    "    \"\"\"\n",
    "    Generates tokens from tweets\n",
    "    \"\"\"\n",
    "    all_text = ' '.join((t for t in tweet_list))\n",
    "    tokens = (TweetTokenizer(preserve_case=False,\n",
    "                            reduce_len=True,\n",
    "                            strip_handles=False)\n",
    "              .tokenize(all_text))\n",
    "    # remove symbol-only tokens for now\n",
    "    tokens = [tok for tok in tokens if not tok in string.punctuation]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = get_all_tokens(pd_data.loc[:,'tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1144055 tokens in total\n"
     ]
    }
   ],
   "source": [
    "print('There are {0} tokens in total'.format(len(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('…', '#notmypresident'), 5861), (('#whytepanther', '#notmypresident'), 2783), (('#notmypresident', '#auditthevote'), 2584), (('#notmypresident', '#notmypresident'), 2121), (('this', 'is'), 2119), (('of', 'the'), 1817), (('#auditthevote', '#notmypresident'), 1741), (('#notmypresident', '#theresistance'), 1678), (('is', 'a'), 1607), (('#notmypresident', '@realdonaldtrump'), 1469), (('donald', 'trump'), 1463), (('trump', 'is'), 1377), (('#notmypresident', '#resist'), 1377), (('in', 'the'), 1333), (('…', '@realdonaldtrump'), 1316), (('to', 'be'), 1252), (('@realdonaldtrump', '#notmypresident'), 1208), (('he', 'is'), 1192), (('is', '#notmypresident'), 1192), (('…', '#whytepanther'), 1151), (('…', '#whytepanther', '#notmypresident'), 1151), (('you', 'are'), 1146), (('#trump', '#notmypresident'), 1119), (('#theresistance', '#notmypresident'), 1050), (('#notmypresident', '#trump'), 1039), (('#notmypresident', '#nevertrump'), 1007), (('...', '#notmypresident'), 994), (('…', 'via'), 974), (('’', 's'), 961), (('#nevertrump', '#notmypresident'), 955)]\n"
     ]
    }
   ],
   "source": [
    "top_grams = Counter(everygrams(tokens, min_len=2, max_len=4)).most_common(30)\n",
    "print(top_grams) # most popular tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = ['english',\n",
    "             'spanish',\n",
    "             'german',\n",
    "             'french',\n",
    "             'italian',\n",
    "            ]\n",
    "# Collect a list of stopwords in order to eleminate them from the \n",
    "stopw = list(set(it.chain.from_iterable((stopwords.words(lang)\n",
    "                                                for lang in languages))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates punctuation words so that they can be removed from tokens along with stopwords\n",
    "\n",
    "def gen_punc(max_length=4):\n",
    "\n",
    "    def punc(length):\n",
    "        return ((''.join(x) for x in it.product(string.punctuation,\n",
    "                                                repeat=length)))\n",
    "    words = it.chain.from_iterable((punc(length)\n",
    "                                    for length in range(max_length+1)))\n",
    "    return list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1083488\n",
      "['tenías', 'auraient', 'serons', 'unserem', 'vous', 'les', 'mais', 'ton', 'lo', 'avranno']\n"
     ]
    }
   ],
   "source": [
    "# Final list of stopwords\n",
    "\n",
    "stopw = list(it.chain(stopw, gen_punc(max_length=4)))\n",
    "print(len(stopw))\n",
    "print(stopw[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid tokenization of url by replacing them with <URL>\n",
    "def replace_urls(in_string, replacement=None):\n",
    "    replacement = '<-URL->' if replacement is None else replacement\n",
    "    pattern = re.compile('(https?://)?(\\w*[.]\\w+)+([/?=&]+\\w+)*')\n",
    "    return re.sub(pattern, replacement, in_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(in_string):\n",
    "    \"\"\"\n",
    "    Convert `in_string` of text to a list of tokens using NLTK's TweetTokenizer\n",
    "    \"\"\"\n",
    "    tokenizer = TweetTokenizer(preserve_case=False,\n",
    "                               reduce_len=True,\n",
    "                               strip_handles=False)\n",
    "    tokens = tokenizer.tokenize(in_string)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unfortunately',\n",
       " '@realdonaldtrump',\n",
       " \"doesn't\",\n",
       " 'understand',\n",
       " 'science',\n",
       " 'or',\n",
       " 'integrity',\n",
       " '.',\n",
       " '#notmypresident',\n",
       " '#dumptrump',\n",
       " 'https://twitter.com/washingtonpost/status/804071010848931840',\n",
       " '…']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tokenizer(pd_data.loc[0,'tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(preprocessor=replace_urls,\n",
    "                      tokenizer=my_tokenizer,\n",
    "                      stop_words=stopw,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2',\n",
       "        preprocessor=<function replace_urls at 0x7f01ac3f9b70>,\n",
       "        smooth_idf=True,\n",
       "        stop_words=['tenías', 'auraient', 'serons', 'unserem', 'vous', 'les', 'mais', 'ton', 'lo', 'avranno', 'fareste', 'dasselbe', 'mie', 'es', 'estuvieseis', 'une', 'hat', 'bist', 'yours', 'estaré', 'haven', 'algunos', 'jedem', 'fuera', 'eines', 'dell', 'estaríamos', 'sehr', 'sera', 'vuestra', 'coi', 'hu...>', '~~~?', '~~~@', '~~~[', '~~~\\\\', '~~~]', '~~~^', '~~~_', '~~~`', '~~~{', '~~~|', '~~~}', '~~~~'],\n",
       "        strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function my_tokenizer at 0x7f01ac710378>, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
