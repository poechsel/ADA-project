{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pierre/.local/lib/python3.7/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib\n",
    "    %matplotlib inline\n",
    "\n",
    "    import findspark\n",
    "    findspark.init()\n",
    "\n",
    "    # Import and start a Spark session.\n",
    "    from pyspark.sql import *\n",
    "    import pyspark.sql.functions as F\n",
    "\n",
    "    spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_insights(months):\n",
    "    return {month: spark.read.parquet('hashtags_insights_{}.parquet'.format(month)) for month in months} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the different hashtags insights for each months. The month of January is omitted as it is corrupted, the month of June is also omitted as it is too small (we only have data for an extract of two days), and the month december does not exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = load_insights(['02', '03', '04', '05', '07', '08', '09', '10', '11'])\n",
    "#hashtags = load_insights(['09', '10', '11'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reasons we didn't understood, our hashtags insights for the month of augusts contained some duplicates rows. Hence, we remove them before continuing our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags['08'] = hashtags['08'].dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_days = [str(i) for i in range(1, 32)]\n",
    "all_months = [str(i).zfill(2) for i in range(2, 13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "allColumns = \\\n",
    "    [\"tag\", \"count\", \"print\"] + \\\n",
    "    [month + \"_print_\" + day for day in all_days for month in all_months] + \\\n",
    "    [month + \"_count_\" + day for day in all_days for month in all_months]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(insights, prefix):\n",
    "    printCols = [c for c in insights.columns if \"print_\" in c]\n",
    "    nameCols = [c for c in insights.columns if \"count_\" in c]\n",
    "    print(insights, prefix)\n",
    "    for x in printCols + nameCols:\n",
    "        if insights.where(F.col(x) != 0).count() == 0:\n",
    "            insights = insights.drop(x)\n",
    "        else:\n",
    "            insights = insights.withColumnRenamed(x, prefix + \"_\" + x)\n",
    "    return insights.drop(\"count\").drop(\"print\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[tag: string, count: bigint, print: bigint, print_1: bigint, print_2: bigint, print_3: bigint, print_4: bigint, print_5: bigint, print_6: bigint, print_7: bigint, print_8: bigint, print_9: bigint, print_10: bigint, print_11: bigint, print_12: bigint, print_13: bigint, print_14: bigint, print_15: bigint, print_16: bigint, print_17: bigint, print_18: bigint, print_19: bigint, print_20: bigint, print_21: bigint, print_22: bigint, print_23: bigint, print_24: bigint, print_25: bigint, print_26: bigint, print_27: bigint, print_28: bigint, print_29: bigint, print_30: bigint, print_31: bigint, count_1: bigint, count_2: bigint, count_3: bigint, count_4: bigint, count_5: bigint, count_6: bigint, count_7: bigint, count_8: bigint, count_9: bigint, count_10: bigint, count_11: bigint, count_12: bigint, count_13: bigint, count_14: bigint, count_15: bigint, count_16: bigint, count_17: bigint, count_18: bigint, count_19: bigint, count_20: bigint, count_21: bigint, count_22: bigint, count_23: bigint, count_24: bigint, count_25: bigint, count_26: bigint, count_27: bigint, count_28: bigint, count_29: bigint, count_30: bigint, count_31: bigint] 02\n",
      "DataFrame[tag: string, count: bigint, print: bigint, print_1: bigint, print_2: bigint, print_3: bigint, print_4: bigint, print_5: bigint, print_6: bigint, print_7: bigint, print_8: bigint, print_9: bigint, print_10: bigint, print_11: bigint, print_12: bigint, print_13: bigint, print_14: bigint, print_15: bigint, print_16: bigint, print_17: bigint, print_18: bigint, print_19: bigint, print_20: bigint, print_21: bigint, print_22: bigint, print_23: bigint, print_24: bigint, print_25: bigint, print_26: bigint, print_27: bigint, print_28: bigint, print_29: bigint, print_30: bigint, print_31: bigint, count_1: bigint, count_2: bigint, count_3: bigint, count_4: bigint, count_5: bigint, count_6: bigint, count_7: bigint, count_8: bigint, count_9: bigint, count_10: bigint, count_11: bigint, count_12: bigint, count_13: bigint, count_14: bigint, count_15: bigint, count_16: bigint, count_17: bigint, count_18: bigint, count_19: bigint, count_20: bigint, count_21: bigint, count_22: bigint, count_23: bigint, count_24: bigint, count_25: bigint, count_26: bigint, count_27: bigint, count_28: bigint, count_29: bigint, count_30: bigint, count_31: bigint] 03\n",
      "DataFrame[tag: string, count: bigint, print: bigint, print_1: bigint, print_2: bigint, print_3: bigint, print_4: bigint, print_5: bigint, print_6: bigint, print_7: bigint, print_8: bigint, print_9: bigint, print_10: bigint, print_11: bigint, print_12: bigint, print_13: bigint, print_14: bigint, print_15: bigint, print_16: bigint, print_17: bigint, print_18: bigint, print_19: bigint, print_20: bigint, print_21: bigint, print_22: bigint, print_23: bigint, print_24: bigint, print_25: bigint, print_26: bigint, print_27: bigint, print_28: bigint, print_29: bigint, print_30: bigint, print_31: bigint, count_1: bigint, count_2: bigint, count_3: bigint, count_4: bigint, count_5: bigint, count_6: bigint, count_7: bigint, count_8: bigint, count_9: bigint, count_10: bigint, count_11: bigint, count_12: bigint, count_13: bigint, count_14: bigint, count_15: bigint, count_16: bigint, count_17: bigint, count_18: bigint, count_19: bigint, count_20: bigint, count_21: bigint, count_22: bigint, count_23: bigint, count_24: bigint, count_25: bigint, count_26: bigint, count_27: bigint, count_28: bigint, count_29: bigint, count_30: bigint, count_31: bigint] 04\n",
      "DataFrame[tag: string, count: bigint, print: bigint, print_1: bigint, print_2: bigint, print_3: bigint, print_4: bigint, print_5: bigint, print_6: bigint, print_7: bigint, print_8: bigint, print_9: bigint, print_10: bigint, print_11: bigint, print_12: bigint, print_13: bigint, print_14: bigint, print_15: bigint, print_16: bigint, print_17: bigint, print_18: bigint, print_19: bigint, print_20: bigint, print_21: bigint, print_22: bigint, print_23: bigint, print_24: bigint, print_25: bigint, print_26: bigint, print_27: bigint, print_28: bigint, print_29: bigint, print_30: bigint, print_31: bigint, count_1: bigint, count_2: bigint, count_3: bigint, count_4: bigint, count_5: bigint, count_6: bigint, count_7: bigint, count_8: bigint, count_9: bigint, count_10: bigint, count_11: bigint, count_12: bigint, count_13: bigint, count_14: bigint, count_15: bigint, count_16: bigint, count_17: bigint, count_18: bigint, count_19: bigint, count_20: bigint, count_21: bigint, count_22: bigint, count_23: bigint, count_24: bigint, count_25: bigint, count_26: bigint, count_27: bigint, count_28: bigint, count_29: bigint, count_30: bigint, count_31: bigint] 05\n",
      "DataFrame[tag: string, count: bigint, print: bigint, print_1: bigint, print_2: bigint, print_3: bigint, print_4: bigint, print_5: bigint, print_6: bigint, print_7: bigint, print_8: bigint, print_9: bigint, print_10: bigint, print_11: bigint, print_12: bigint, print_13: bigint, print_14: bigint, print_15: bigint, print_16: bigint, print_17: bigint, print_18: bigint, print_19: bigint, print_20: bigint, print_21: bigint, print_22: bigint, print_23: bigint, print_24: bigint, print_25: bigint, print_26: bigint, print_27: bigint, print_28: bigint, print_29: bigint, print_30: bigint, print_31: bigint, count_1: bigint, count_2: bigint, count_3: bigint, count_4: bigint, count_5: bigint, count_6: bigint, count_7: bigint, count_8: bigint, count_9: bigint, count_10: bigint, count_11: bigint, count_12: bigint, count_13: bigint, count_14: bigint, count_15: bigint, count_16: bigint, count_17: bigint, count_18: bigint, count_19: bigint, count_20: bigint, count_21: bigint, count_22: bigint, count_23: bigint, count_24: bigint, count_25: bigint, count_26: bigint, count_27: bigint, count_28: bigint, count_29: bigint, count_30: bigint, count_31: bigint] 07\n",
      "DataFrame[tag: string, count: bigint, print: bigint, print_1: bigint, print_2: bigint, print_3: bigint, print_4: bigint, print_5: bigint, print_6: bigint, print_7: bigint, print_8: bigint, print_9: bigint, print_10: bigint, print_11: bigint, print_12: bigint, print_13: bigint, print_14: bigint, print_15: bigint, print_16: bigint, print_17: bigint, print_18: bigint, print_19: bigint, print_20: bigint, print_21: bigint, print_22: bigint, print_23: bigint, print_24: bigint, print_25: bigint, print_26: bigint, print_27: bigint, print_28: bigint, print_29: bigint, print_30: bigint, print_31: bigint, count_1: bigint, count_2: bigint, count_3: bigint, count_4: bigint, count_5: bigint, count_6: bigint, count_7: bigint, count_8: bigint, count_9: bigint, count_10: bigint, count_11: bigint, count_12: bigint, count_13: bigint, count_14: bigint, count_15: bigint, count_16: bigint, count_17: bigint, count_18: bigint, count_19: bigint, count_20: bigint, count_21: bigint, count_22: bigint, count_23: bigint, count_24: bigint, count_25: bigint, count_26: bigint, count_27: bigint, count_28: bigint, count_29: bigint, count_30: bigint, count_31: bigint] 08\n",
      "DataFrame[tag: string, count: bigint, print: bigint, print_1: bigint, print_2: bigint, print_3: bigint, print_4: bigint, print_5: bigint, print_6: bigint, print_7: bigint, print_8: bigint, print_9: bigint, print_10: bigint, print_11: bigint, print_12: bigint, print_13: bigint, print_14: bigint, print_15: bigint, print_16: bigint, print_17: bigint, print_18: bigint, print_19: bigint, print_20: bigint, print_21: bigint, print_22: bigint, print_23: bigint, print_24: bigint, print_25: bigint, print_26: bigint, print_27: bigint, print_28: bigint, print_29: bigint, print_30: bigint, print_31: bigint, count_1: bigint, count_2: bigint, count_3: bigint, count_4: bigint, count_5: bigint, count_6: bigint, count_7: bigint, count_8: bigint, count_9: bigint, count_10: bigint, count_11: bigint, count_12: bigint, count_13: bigint, count_14: bigint, count_15: bigint, count_16: bigint, count_17: bigint, count_18: bigint, count_19: bigint, count_20: bigint, count_21: bigint, count_22: bigint, count_23: bigint, count_24: bigint, count_25: bigint, count_26: bigint, count_27: bigint, count_28: bigint, count_29: bigint, count_30: bigint, count_31: bigint] 09\n",
      "DataFrame[tag: string, count: bigint, print: bigint, print_1: bigint, print_2: bigint, print_3: bigint, print_4: bigint, print_5: bigint, print_6: bigint, print_7: bigint, print_8: bigint, print_9: bigint, print_10: bigint, print_11: bigint, print_12: bigint, print_13: bigint, print_14: bigint, print_15: bigint, print_16: bigint, print_17: bigint, print_18: bigint, print_19: bigint, print_20: bigint, print_21: bigint, print_22: bigint, print_23: bigint, print_24: bigint, print_25: bigint, print_26: bigint, print_27: bigint, print_28: bigint, print_29: bigint, print_30: bigint, print_31: bigint, count_1: bigint, count_2: bigint, count_3: bigint, count_4: bigint, count_5: bigint, count_6: bigint, count_7: bigint, count_8: bigint, count_9: bigint, count_10: bigint, count_11: bigint, count_12: bigint, count_13: bigint, count_14: bigint, count_15: bigint, count_16: bigint, count_17: bigint, count_18: bigint, count_19: bigint, count_20: bigint, count_21: bigint, count_22: bigint, count_23: bigint, count_24: bigint, count_25: bigint, count_26: bigint, count_27: bigint, count_28: bigint, count_29: bigint, count_30: bigint, count_31: bigint] 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[tag: string, count: bigint, print: bigint, print_1: bigint, print_2: bigint, print_3: bigint, print_4: bigint, print_5: bigint, print_6: bigint, print_7: bigint, print_8: bigint, print_9: bigint, print_10: bigint, print_11: bigint, print_12: bigint, print_13: bigint, print_14: bigint, print_15: bigint, print_16: bigint, print_17: bigint, print_18: bigint, print_19: bigint, print_20: bigint, print_21: bigint, print_22: bigint, print_23: bigint, print_24: bigint, print_25: bigint, print_26: bigint, print_27: bigint, print_28: bigint, print_29: bigint, print_30: bigint, print_31: bigint, count_1: bigint, count_2: bigint, count_3: bigint, count_4: bigint, count_5: bigint, count_6: bigint, count_7: bigint, count_8: bigint, count_9: bigint, count_10: bigint, count_11: bigint, count_12: bigint, count_13: bigint, count_14: bigint, count_15: bigint, count_16: bigint, count_17: bigint, count_18: bigint, count_19: bigint, count_20: bigint, count_21: bigint, count_22: bigint, count_23: bigint, count_24: bigint, count_25: bigint, count_26: bigint, count_27: bigint, count_28: bigint, count_29: bigint, count_30: bigint, count_31: bigint] 11\n"
     ]
    }
   ],
   "source": [
    "insights = [rename_columns(hashtags[key], key) for key in hashtags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def joinAll(dfs):\n",
    "    return reduce(lambda prev, cur: cur.join(prev, on='tag', how='outer'), dfs)\n",
    "unifiedInsights = joinAll(insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ee79c5600306>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0munifiedInsights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unifiedinsights.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/apache-spark/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mparquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionBy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_opts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apache-spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/opt/apache-spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/apache-spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#unifiedInsights.write.mode(\"overwrite\").parquet(\"unifiedinsights.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unifiedInsights = spark.read.parquet(\"unifiedinsights.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unifiedInsights = unifiedInsights.fillna(0).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_columns = [c for c in unifiedInsights.columns if \"count\" in c]\n",
    "print_columns = [c for c in unifiedInsights.columns if \"print\" in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unifiedInsights = unifiedInsights.withColumn(\"count\", sum(F.col(c) for c in count_columns))\n",
    "unifiedInsights = unifiedInsights.withColumn(\"print\", sum(F.col(c) for c in print_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "unifiedInsights.write.mode(\"overwrite\").parquet(\"hashtags-insights.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(print_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "insights = spark.read.parquet(\"hashtags-insights.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15177260"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unifiedInsights.select(F.col('tag')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|        tag|\n",
      "+-----------+\n",
      "|000bloodrun|\n",
      "|  005GOBLIN|\n",
      "|  005GOBLIN|\n",
      "|  005GOBLIN|\n",
      "|     007E8C|\n",
      "|     010tml|\n",
      "|     010tml|\n",
      "|     010tml|\n",
      "|       016s|\n",
      "|      01트친소|\n",
      "|   024_Full|\n",
      "|      02AGO|\n",
      "|      02AGO|\n",
      "|      02AGO|\n",
      "|      02May|\n",
      "|    02년생입니당|\n",
      "|     0309상암|\n",
      "|03Kasım2002|\n",
      "|   040zwemt|\n",
      "|    04Junio|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "insights.select(F.col('tag')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function which will allow us to unify the columns of every sub dataframes by renaming some columns and adding some others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(insights, prefix):\n",
    "    printCols = [c for c in insights.columns if \"print_\" in c]\n",
    "    nameCols = [c for c in insights.columns if \"count_\" in c]\n",
    "    print(insights, prefix)\n",
    "    for x in printCols + nameCols:\n",
    "        insights = insights.withColumnRenamed(x, prefix + \"_\" + x)\n",
    "    columns = insights.columns\n",
    "    for i, x in enumerate(allColumns):\n",
    "        if i % 50 == 0:\n",
    "            print(i, len(allColumns))\n",
    "        if not x in columns:\n",
    "            insights = insights.withColumn(x, F.lit(0).cast(\"long\"))\n",
    "    return insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then apply this function to all of our insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[tag: string, count: bigint, print: bigint, print_1: bigint, print_2: bigint, print_3: bigint, print_4: bigint, print_5: bigint, print_6: bigint, print_7: bigint, print_8: bigint, print_9: bigint, print_10: bigint, print_11: bigint, print_12: bigint, print_13: bigint, print_14: bigint, print_15: bigint, print_16: bigint, print_17: bigint, print_18: bigint, print_19: bigint, print_20: bigint, print_21: bigint, print_22: bigint, print_23: bigint, print_24: bigint, print_25: bigint, print_26: bigint, print_27: bigint, print_28: bigint, print_29: bigint, print_30: bigint, print_31: bigint, count_1: bigint, count_2: bigint, count_3: bigint, count_4: bigint, count_5: bigint, count_6: bigint, count_7: bigint, count_8: bigint, count_9: bigint, count_10: bigint, count_11: bigint, count_12: bigint, count_13: bigint, count_14: bigint, count_15: bigint, count_16: bigint, count_17: bigint, count_18: bigint, count_19: bigint, count_20: bigint, count_21: bigint, count_22: bigint, count_23: bigint, count_24: bigint, count_25: bigint, count_26: bigint, count_27: bigint, count_28: bigint, count_29: bigint, count_30: bigint, count_31: bigint] 02\n",
      "0 685\n",
      "50 685\n",
      "100 685\n",
      "150 685\n",
      "200 685\n",
      "250 685\n",
      "300 685\n",
      "350 685\n",
      "400 685\n",
      "450 685\n",
      "500 685\n",
      "550 685\n"
     ]
    }
   ],
   "source": [
    "insights = [rename_columns(hashtags[key], key) for key in hashtags]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge every insights in one unique dataframe. We have to make sure that every columns is in the same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def unionAll(dfs):\n",
    "    return reduce(DataFrame.union, dfs)\n",
    "unifiedInsights = unionAll([i.select(allColumns) for i in insights])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As some hashtags might appear in different months, we need to merge duplicates occurencies of the same hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToSum = [x for x in unifiedInsights.columns if x != \"tag\"]\n",
    "aggExpressions = [F.sum(F.col(col)).alias(col) for col in columnsToSum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unifiedInsightsGB = unifiedInsights.groupBy('tag').agg(*aggExpressions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unifiedInsightsGB.write.mode(\"overwrite\").parquet(\"unifiedinsights.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unifiedInsights = spark.read.parquet(\"unifiedinsights.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unifiedInsights.where(F.col('11_print_4') != 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags[\"11\"].where(F.col(\"print_4\") != 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in allColumns:\n",
    "    if unifiedInsights.where(F.col(x) != 0).count() == 0:\n",
    "        unifiedInsights = unifiedInsights.drop(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in unifiedInsights.columns if \"11\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unifiedInsights.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in unifiedInsights.columns if \"01\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unifiedInsights.write.mode(\"overwrite\").parquet(\"insights.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unifiedInsights.where(F.col('03_count_1') != 0).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags[\"03\"].columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
